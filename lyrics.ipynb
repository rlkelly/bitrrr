{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pattern\n",
    "from pattern.web import URL, DOM, plaintext\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import random\n",
    "\n",
    "filedic = {}\n",
    "for each in os.listdir(os.getcwd())[2:]:\n",
    "    if (each != \"lyrics.ipynb\") and (each != 'Untitled.ipynb'):\n",
    "        filedic[each] = listdir(each)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyricsdic = defaultdict(list)\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "remove_list = ['verse','hook','chorus', '','choruslloyd banks', '50 cent', 'outro','bridge', 'chorus', 'lyrics', 'lloyd banks', 'rick ross','lil wayne', 'da', 'dem', 'im', 'ya', 'dat', 'tony yayo', 'banks yay 50',\n",
    "              'verse 1 tony yayo', 'verse 4 lloyd banks', 'verse 5 50 cent', 'verse 2 tony yayo', 'verse 1 50 cent', 'chorus 50 cent', 'intro 50 cent', 'biggie sample  in the background throughout the song', 'verse 3  tony yayo', 'verse 1  50 cent','chorus  50 cent','verse 2  lloyd banks','verse 2 lloyd banks', 'verse 6 tony yayo', 'verse 4 yony yayo']\n",
    "\n",
    "for k,v in filedic.iteritems():\n",
    "    for link in v:\n",
    "        page = open(k+'/'+link).read()\n",
    "        dom = DOM(page)\n",
    "        lyrics = dom('.lyrics')[0]\n",
    "        p = plaintext(lyrics.content)\n",
    "        p = ''.join(ch for ch in p if ch not in exclude)\n",
    "        p = p.splitlines()\n",
    "        lyricsdic[k].append(filter(lambda x: x.lower() not in remove_list, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lyricsdic['50cent'][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lineslist = []\n",
    "remove_list = ['verse','hook','chorus', '','choruslloyd banks', '50 cent', 'outro','bridge', 'chorus', 'lyrics', 'lloyd banks', 'rick ross','lil wayne', 'da', 'dem', 'im', 'ya', 'dat', 'tony yayo', 'banks yay 50',\n",
    "              'verse 1 tony yayo', 'verse 4 lloyd banks', 'verse 5 50 cent', 'verse 2 tony yayo', 'verse 1 50 cent', 'chorus 50 cent', 'intro 50 cent', 'biggie sample  in the background throughout the song', 'verse 3  tony yayo', 'verse 1  50 cent','chorus  50 cent','verse 2  lloyd banks','verse 2 lloyd banks', 'verse 6 tony yayo', 'verse 4 yony yayo']\n",
    "exportlist = []\n",
    "for each in lyricslist:\n",
    "    lineslist.append(each.splitlines())\n",
    "lineslist = np.array(lineslist)\n",
    "for each in lineslist:\n",
    "    exportlist.append(filter(lambda x: x.lower() not in remove_list, each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('picklelyrics', 'wb')\n",
    "\n",
    "pickle.dump(lyricsdic, f)\n",
    "\n",
    "# import simplejson\n",
    "# f = open('lyricsarchive.txt', 'w')\n",
    "# simplejson.dump(exportlist, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenlist = []\n",
    "\n",
    "for lyrics in lyricslist:\n",
    "    tokens = nltk.word_tokenize(lyrics)\n",
    "    tokenlist.extend([w for w in tokens if w.lower() not in stopwords.words('english')])\n",
    "\n",
    "import random\n",
    "\n",
    "class Markov(object):\n",
    "\n",
    "    def __init__(self, words):\n",
    "        self.cache = {}\n",
    "        #self.open_file = open_file\n",
    "        self.words = words\n",
    "        self.word_size = len(self.words)\n",
    "        self.database()\n",
    "\n",
    "    def file_to_words(self):\n",
    "        self.open_file.seek(0)\n",
    "        data = self.open_file.read()\n",
    "        words = data.split()\n",
    "        return words\n",
    "\n",
    "    def triples(self):\n",
    "        if len(self.words) < 3:\n",
    "            return\n",
    "        for i in range(len(self.words) - 2):\n",
    "            yield (self.words[i], self.words[i+1], self.words[i+2])\n",
    "\n",
    "    def database(self):\n",
    "        for w1, w2, w3 in self.triples():\n",
    "            key = (w1, w2)\n",
    "            if key in self.cache:\n",
    "                self.cache[key].append(w3)\n",
    "            else:\n",
    "                self.cache[key] = [w3]\n",
    "\n",
    "    def generate_markov_text(self, size=25):\n",
    "        seed = random.randint(0, self.word_size-3)\n",
    "        seed_word, next_word = self.words[seed], self.words[seed+1]\n",
    "        w1, w2 = seed_word, next_word\n",
    "        gen_words = []\n",
    "        for i in xrange(size):\n",
    "            gen_words.append(w1)\n",
    "            w1, w2 = w2, random.choice(self.cache[(w1, w2)])\n",
    "        gen_words.append(w2)\n",
    "        return ' '.join(gen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'hesitate pull right back Tell something good baby Boss done took Im back brother went Thats tomb say Right government Dumile Either unmarked engraved hey whos say Pass mic like yin yang Clang Crime dont pay ya taxes Fore spit name backwards Aaask around Im back nigga hold uh SmithNWesson Im'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark = Markov(tokenlist)\n",
    "mark.generate_markov_text(size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features for each cluster:\n",
      "0: lyrics, song, help, visitors, submit\n",
      "1: 50, cent, im, nigga, niggas\n",
      "2: like, im, got, know, tha\n",
      "3: nigga, niggas, im, got, like\n",
      "4: girl, like, baby, im, love\n",
      "5: im, like, bitch, nigga, got\n",
      "6: im, like, got, dont, money\n",
      "7: da, im, ya, dat, like\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(lyricslist)\n",
    "features = vectorizer.get_feature_names()\n",
    "kmeans = KMeans()\n",
    "kmeans.fit(X)\n",
    "\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-6:-1]\n",
    "print \"top features for each cluster:\"\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print \"%d: %s\" % (num, \", \".join(features[i] for i in centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'aglo',\n",
       " u'aglow',\n",
       " u'belleau',\n",
       " u'below',\n",
       " u'bleau',\n",
       " u'blow',\n",
       " u'blowe',\n",
       " u'boileau',\n",
       " u'celo',\n",
       " u'cloe',\n",
       " u'clow',\n",
       " u'enloe',\n",
       " u'enlow',\n",
       " u'enslow',\n",
       " u'flo',\n",
       " u'floe',\n",
       " u'flow',\n",
       " u'flowe',\n",
       " u'furlaud',\n",
       " u'glo',\n",
       " u'gloe',\n",
       " u'glow',\n",
       " u'groleau',\n",
       " u'guillot',\n",
       " u'hello',\n",
       " u'inlow',\n",
       " u'ledlow',\n",
       " u'leleux',\n",
       " u'lo',\n",
       " u'loe',\n",
       " u'loew',\n",
       " u'loewe',\n",
       " u'loh',\n",
       " u'low',\n",
       " u'lowe',\n",
       " u'mealo',\n",
       " u'overflow',\n",
       " u'plough',\n",
       " u'rouleau',\n",
       " u'sloe',\n",
       " u'slow',\n",
       " u'soileau',\n",
       " u'tableau',\n",
       " u'tableaux',\n",
       " u'tourtelot',\n",
       " u'valleau',\n",
       " u'veilleux'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rhyme(inp, level):\n",
    "    entries = nltk.corpus.cmudict.entries()\n",
    "    syllables = [(word, syl) for word, syl in entries if word == inp]\n",
    "    rhymes = []\n",
    "    for (word, syllable) in syllables:\n",
    "        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
    "    return set(rhymes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
